[2021-11-27 04:56:33,075] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: daily-scraping.scraping manual__2021-11-26T21:56:30.466355+00:00 [queued]>
[2021-11-27 04:56:33,082] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: daily-scraping.scraping manual__2021-11-26T21:56:30.466355+00:00 [queued]>
[2021-11-27 04:56:33,082] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2021-11-27 04:56:33,082] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2021-11-27 04:56:33,082] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2021-11-27 04:56:33,091] {taskinstance.py:1262} INFO - Executing <Task(BashOperator): scraping> on 2021-11-26 21:56:30.466355+00:00
[2021-11-27 04:56:33,094] {standard_task_runner.py:52} INFO - Started process 19607 to run task
[2021-11-27 04:56:33,099] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'daily-scraping', 'scraping', 'manual__2021-11-26T21:56:30.466355+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/scraping.py', '--cfg-path', '/var/folders/hj/g8v71bv11_gb814qbbwch8zc0000gn/T/tmpud8_i6cm', '--error-file', '/var/folders/hj/g8v71bv11_gb814qbbwch8zc0000gn/T/tmp039b2tfs']
[2021-11-27 04:56:33,101] {standard_task_runner.py:77} INFO - Job 2: Subtask scraping
[2021-11-27 04:56:33,136] {logging_mixin.py:109} INFO - Running <TaskInstance: daily-scraping.scraping manual__2021-11-26T21:56:30.466355+00:00 [running]> on host 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa
[2021-11-27 04:56:33,183] {taskinstance.py:1427} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@example.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=daily-scraping
AIRFLOW_CTX_TASK_ID=scraping
AIRFLOW_CTX_EXECUTION_DATE=2021-11-26T21:56:30.466355+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-11-26T21:56:30.466355+00:00
[2021-11-27 04:56:33,184] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/hj/g8v71bv11_gb814qbbwch8zc0000gn/T
[2021-11-27 04:56:33,185] {subprocess.py:74} INFO - Running command: ['bash', '-c', '/Users/Home/Airflow/tasks/scraping.py /Users/Home/Airflow/down']
[2021-11-27 04:56:33,192] {subprocess.py:85} INFO - Output:
[2021-11-27 05:11:20,210] {base_job.py:230} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: task_instance.run_id

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/jobs/base_job.py", line 226, in heartbeat
    self.heartbeat_callback(session=session)
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/jobs/local_task_job.py", line 184, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 731, in refresh_from_db
    ti = qry.first()
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/usr/local/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: task_instance.run_id
[SQL: SELECT task_instance.try_number AS task_instance_try_number, task_instance.task_id AS task_instance_task_id, task_instance.dag_id AS task_instance_dag_id, task_instance.run_id AS task_instance_run_id, task_instance.start_date AS task_instance_start_date, task_instance.end_date AS task_instance_end_date, task_instance.duration AS task_instance_duration, task_instance.state AS task_instance_state, task_instance.max_tries AS task_instance_max_tries, task_instance.hostname AS task_instance_hostname, task_instance.unixname AS task_instance_unixname, task_instance.job_id AS task_instance_job_id, task_instance.pool AS task_instance_pool, task_instance.pool_slots AS task_instance_pool_slots, task_instance.queue AS task_instance_queue, task_instance.priority_weight AS task_instance_priority_weight, task_instance.operator AS task_instance_operator, task_instance.queued_dttm AS task_instance_queued_dttm, task_instance.queued_by_job_id AS task_instance_queued_by_job_id, task_instance.pid AS task_instance_pid, task_instance.executor_config AS task_instance_executor_config, task_instance.external_executor_id AS task_instance_external_executor_id, task_instance.trigger_id AS task_instance_trigger_id, task_instance.trigger_timeout AS task_instance_trigger_timeout, task_instance.next_method AS task_instance_next_method, task_instance.next_kwargs AS task_instance_next_kwargs, dag_run_1.state AS dag_run_1_state, dag_run_1.id AS dag_run_1_id, dag_run_1.dag_id AS dag_run_1_dag_id, dag_run_1.queued_at AS dag_run_1_queued_at, dag_run_1.execution_date AS dag_run_1_execution_date, dag_run_1.start_date AS dag_run_1_start_date, dag_run_1.end_date AS dag_run_1_end_date, dag_run_1.run_id AS dag_run_1_run_id, dag_run_1.creating_job_id AS dag_run_1_creating_job_id, dag_run_1.external_trigger AS dag_run_1_external_trigger, dag_run_1.run_type AS dag_run_1_run_type, dag_run_1.conf AS dag_run_1_conf, dag_run_1.data_interval_start AS dag_run_1_data_interval_start, dag_run_1.data_interval_end AS dag_run_1_data_interval_end, dag_run_1.last_scheduling_decision AS dag_run_1_last_scheduling_decision, dag_run_1.dag_hash AS dag_run_1_dag_hash 
FROM task_instance JOIN dag_run AS dag_run_1 ON dag_run_1.dag_id = task_instance.dag_id AND dag_run_1.run_id = task_instance.run_id 
WHERE task_instance.dag_id = ? AND task_instance.task_id = ? AND task_instance.run_id = ?
 LIMIT ? OFFSET ?]
[parameters: ('daily-scraping', 'scraping', 'manual__2021-11-26T21:56:30.466355+00:00', 1, 0)]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2021-11-27 05:11:25,284] {local_task_job.py:211} WARNING - State of this instance has been externally set to None. Terminating instance.
[2021-11-27 05:11:25,303] {process_utils.py:100} INFO - Sending Signals.SIGTERM to GPID 19607
[2021-11-27 05:11:25,319] {taskinstance.py:1411} ERROR - Received SIGTERM. Terminating subprocesses.
[2021-11-27 05:11:25,327] {subprocess.py:99} INFO - Sending SIGTERM signal to process group
[2021-11-27 05:11:25,356] {taskinstance.py:1703} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/bash.py", line 178, in execute
    result = self.subprocess_hook.run_command(
  File "/usr/local/lib/python3.9/site-packages/airflow/hooks/subprocess.py", line 87, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b''):
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1413, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2021-11-27 05:11:25,372] {taskinstance.py:1270} INFO - Marking task as FAILED. dag_id=daily-scraping, task_id=scraping, execution_date=20211126T215630, start_date=20211126T215633, end_date=20211126T221125
[2021-11-27 05:11:25,397] {standard_task_runner.py:88} ERROR - Failed to execute job 2 for task scraping
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/usr/local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/usr/local/lib/python3.9/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1332, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1458, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1514, in _execute_task
    result = execute_callable(context=context)
  File "/usr/local/lib/python3.9/site-packages/airflow/operators/bash.py", line 178, in execute
    result = self.subprocess_hook.run_command(
  File "/usr/local/lib/python3.9/site-packages/airflow/hooks/subprocess.py", line 87, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b''):
  File "/usr/local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 1413, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2021-11-27 05:11:25,444] {process_utils.py:66} INFO - Process psutil.Process(pid=19607, status='terminated', exitcode=1, started='04:56:33') (19607) terminated with exit code 1
[2021-11-27 05:11:25,447] {process_utils.py:66} INFO - Process psutil.Process(pid=19608, status='terminated', started='04:56:33') (19608) terminated with exit code None
